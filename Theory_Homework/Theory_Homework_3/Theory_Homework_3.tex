%% This is LaTeX template for preparing papers for Publ. Inst. Math.; version of 12.12.2013
%% Please delete everything begining with %% (DOUBLE %).

% Submission number: please insert
\documentclass[a4paper]{amsproc}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amscd} %% Package for commutative diagrams
%\usepackage[dvips]{graphicx} %% Package for inserting illustrations/figures

%% The following packages are useful (you may want to use them):
%\usepackage{refcheck} %% Checks whether enumerated equations are referred to or not.
                       %% Please remove unnecessary numbers.
%\usepackage{cmdtrack} %% Checks whether all author defined macros are used or not
                       %% (see the end of .log file); unused ones should be removed.
%% Both of the packages have some limitations---consult package documentations.

\theoremstyle{plain}
 \newtheorem*{thm}{Theorem}
 \newtheorem{prop}{Proposition}[section]
 \newtheorem{lem}{Lemma}[section]
 \newtheorem{cor}{Corollary}[section]
\theoremstyle{definition}
 \newtheorem{exm}{Example}[section]
 \newtheorem{dfn}{Definition}[section]
\theoremstyle{remark}
 \newtheorem{rem}{Remark}[section]
 \numberwithin{equation}{section}

%% Please, do not change the following four lines:
\renewcommand{\le}{\leqslant}\renewcommand{\leq}{\leqslant}
\renewcommand{\ge}{\geqslant}\renewcommand{\geq}{\geqslant}
\renewcommand{\setminus}{\smallsetminus}
\setlength{\textwidth}{28cc} \setlength{\textheight}{42cc}


% \let\oldequation=\equation
% \let\endoldequation=\endequation
% \renewenvironment{equation}{\begin{oldequation}}{\end{oldequation}\vspace{1mm}}

\providecommand{\norm}[1]{\lVert#1 \rVert}
\providecommand{\R}{\begin{pmatrix} R \\ 0 \end{pmatrix}}
\providecommand{\Q}{\begin{pmatrix} Q_1^{T} \\ Q_2^{T} \end{pmatrix}}
\providecommand{\SVD}{\begin{pmatrix} \Sigma \\ 0 \end{pmatrix}}
\providecommand{\SVDr}{\begin{pmatrix} \Sigma_1 & 0 \\ 0 & 0 \end{pmatrix}}
\providecommand{\V}{\begin{pmatrix} V_1^{T} \\ V_2^{T} \end{pmatrix}}
\providecommand{\U}{\begin{pmatrix} U_1  U_2 \end{pmatrix}}
\providecommand{\Vr}{\begin{pmatrix} v_1^{T} \\ \vdots \\ v_r^{T} \end{pmatrix}}
\providecommand{\Vn}{\begin{pmatrix} v_1^{T} \\ \vdots \\ v_n^{T} \end{pmatrix}}
\providecommand{\Vni}{\begin{pmatrix} v_{1i} \dots v_{ni}\end{pmatrix}}
\providecommand{\B}{\begin{pmatrix} b_1^{T} \\ \vdots \\ b_n^{T} \end{pmatrix}}

\providecommand{\F}{\begin{pmatrix} w^{(k_1)} \hdots w^{(k_M)} \end{pmatrix}}
\providecommand{\fourier}{\begin{pmatrix} \langle f^h, w^{(k_1)} \rangle \\ \hdots \vspace{1mm} \\ \langle f^h, w^{(k_M)} \rangle \end{pmatrix}}

\title[MAT 228A Theory Homework 3]{MAT 228A Theory Homework 3}

% \subjclass[2010]{Primary REQUIRED; Secondary OPTIONAL}

%% Please use the newest classification -- 2010
%% available at  http://msc2010.org/MSC-2010-server.html
%% and the newest amsproc.cls -- from 2009!!
%% Please, classify to the third level,
%% e.g., 26A and 26Axx are not satisfsctory.

% \keywords{optional, but desirable}

\author[Cherkashin]{\bfseries Ivan Cherkashin}

% \address{
% Department of Mathematics \\ % \hfill (Received 00 00 2010)\\
% Our University   \\ %\hfill (Revised  00 00 2010)\\
% Town\\
% Country}
% \email{user@server}

%% OTHER AUTHOR(S):
%\author[]{}
%\address{ }
%\email{}

% \thanks{Partially supported by ... } %% optional

% \dedicatory{Communicated by }
%% We use this for communication information.
%% If you want do dedicate your paper to somebody, then please use \thanks{}

\begin{document}

%{\begin{flushleft}\baselineskip9pt\scriptsize
%PUBLICATIONS DE L'INSTITUT MATH\'EMATIQUE\newline
%Nouvelle s\'erie, tome 91(105) (2012), od--do \hfill DOI:
%\end{flushleft}}
\vspace{18mm} \setcounter{page}{1} \thispagestyle{empty}


% \begin{abstract}
% An abstract is OBLIGATORY!
% Please do not use author defined macros in the abstract
% and avoid references to anything in the paper,
% since the abstract will be detached from the article.
% \end{abstract}

\maketitle

\section*{Problem 1}

\begin{thm} \label{} 
A linear finite-difference method $$(Lu^n)_i = \sum\limits_{s} c_s u^{n}_{i+s}$$ \\ is consistent $ \Longleftrightarrow 
\sum\limits_{s} c_s = 1 ~ \wedge ~ \sum\limits_{s} c_s s = -\sigma$

\end{thm}

\begin{proof}

The order of the truncation error is $ O(\frac{e^{-\sigma\beta} - \lambda(\beta)}{\beta})$: therefore, consistency requires and implies that the order of the truncation error is at least $O(\beta)$ $\Longleftrightarrow$ the first two terms of the Taylor series of the symbol $\lambda(\beta) = \sum\limits_{s} c_s e^{is\beta}$ are equal to the first two terms of the Taylor series of $e^{-i\sigma\beta}$, i.e.

\begin{equation}\label{eq:1.1}
1 - i \sigma \beta = \lambda(0) + \beta\lambda_{\beta}(0) = \sum\limits_{s} c_s + \beta i \sum\limits_{s} c_s s \Longrightarrow \sum\limits_{s} c_s = 1 ~ \wedge ~ \sum\limits_{s} c_s s = -\sigma
\end{equation}

\subsubsection*{Observation}

In case all $c_s \ge 0$, the first condition means that $c_s$ form a discrete probability distribution, and the second means that the mathematical expectation (i.e. average) of the index offsets $s$ relative to $i$ must be equal $-\sigma$. One possible physical interpretation of this requirement is the fact that a closed system that relies on information from the ``future`` (i.e. the case $\sum\limits_{s} c_s s \ge 0$) is non-physical, or at least not observable. Indeed, real observable physical processes are stable: otherwise, instability leads to a qualitative change of the system until it reaches equilibrium, but by then the previous identity and information about the system will have disappeared, hence it is impossible to observe it (unless the power of measurement devices is able to resolve time and space to sufficiently small scales, but that means the system cannot be considered closed anymore, since such precise measurements supply significant amount of energy to the system). 

Also, entropy is higher behind the wave than in front, since real transport processes are irreversible. Hence, when more information is used from the front of the wave than from the back, entropy can decrease, which cannot happen in a real system. Therefore, the information (entropy) balance must be, even slightly, in favor of the information behind the wave, hence the negative sign of the mathematical expectation of the offsets. That means that the information (entropy) flux from negative offsets (cells behind the wave) must dominate over the flux from the positive offsets (front cells).

There is a little connection with probability theory and convex geometry. From this perspective, the discreet evolution operator $L$ can be seen as a doubly stochastic matrix (Proof: Each column, as well as each row, contains all of $c_s$, which add up to $1$: this is due to multidiagonal structure of $L$). That means that consistent finite difference methods form a convex set, because doubly stochastic matrixes form one. Moreover, the fact that every discreet evolution operator is represented as a linear combination of shift operators is a consequence of Caratheodory's theorem for a simplex: every element of a simplex can be uniquely represented as a convex combination of its exterior points. In our case, the exterior points are permutation matrices (shift operators). 

Finally, a stochastic matrix can be seen as a matrix of transition probabilities of a stationary finite-state Markov chain. Then the components of the numerical solution can be interpreted as mathematical expectations of the values at the cells of the stencil at the previous time step. Since the entropy of a Markov chain is maximized when it reaches its stationary transition probability distribution, it is now evident why stable numerical transport processes reach equilibrium: the solution tends to a constant, because in this state the entropy is maximized.  

Now it is possible to prove why consistent linear numerical schemes converge to constant solution and preserve its $L^1$ norm (which can be mass or any other conserved quantity that is being transported). 

Indeed, since the method is consistent, the vector of ones $\Lambda_1 = \begin{pmatrix} 1 \\ \vdots \\ 1 \end{pmatrix}$ is an eigenvector of the discreet evolution operator $L$ with the corresponding eigenvalue of $1$. All other eigenvalues are less than one by absolute value since $\norm{L}_1 = 1$ bounds all the eigenvalues. Therefore, for any initial data vector $u_{0}h$ (assuming it is physical, i.e. all of its components are nonnegative)\footnote{$h = \frac{1}{M}$, $M$ is the number of grid cells: it is included to be consistent with the discreet $L^1$ norm and regular one-norm of $\mathbb{R}^M$, i.e. $\norm{u_0}_{L^1} = \norm{u_{0}h}_1 $}
for very large times $L^n[{u_0}h]$ will converge to 
$$u_\infty = \langle u_{0}h, \Lambda_1 \rangle \Lambda_1 = \norm{u_{0}h}_1 \Lambda_1 = \norm{u_{0}}_{L^1} \Lambda_1$$
Since 
$$\norm{\Lambda_1}_1 = M \Longrightarrow \norm{\Lambda_1}_{L^1} = h\norm{\Lambda_1}_1 = 1$$
it follows, finally, that $$\norm{u_\infty}_{L^1} = \norm{u_{0}}_{L^1} \norm{\Lambda_1}_{L^1} = \norm{u_{0}}_{L^1} $$  

\end{proof}

\section*{Problem 2}

\begin{thm} \label{some label} 
A linear finite-difference method $$(Lu^n)_i = \sum\limits_{s} c_s u^{n}_{i+s}$$ is second order accurate $\sum\limits_{s} c_s s^2 = \sigma^2$ 
\end{thm}

\begin{proof}

The order of the truncation error is $ O(\frac{e^{-\sigma\beta} - \lambda(\beta)}{\beta})$: therefore, second-order convergence requires and implies that the order of the truncation error is at least $O(\beta^2) \Longrightarrow$ the first three terms of the Taylor series of the symbol $\lambda(\beta) = \sum\limits_{s} c_s e^{is\beta}$ and $e^{-i\sigma\beta}$ must be equal, i.e. for the third term:

\begin{equation}\label{eq:2.1}  
\frac{-\sigma^2\beta^2}{2} = \frac{\beta^2}{2}\lambda_{\beta\beta}(0) = \frac{\beta^2}{2}\sum\limits_{s} -c_s s^2 \Longrightarrow \sum\limits_{s} c_s s^2 = \sigma^2
\end{equation}

\end{proof}

\section*{Problem 3}

\begin{thm} \label{some label}
Only even powers of $\beta$ appear in the Taylor expansion (about 0) of $\lvert \lambda(\beta) \rvert$
\end{thm}

\begin{proof}
$\lvert \lambda(-\beta) \rvert = \lvert \overline{\lambda(\beta)} \rvert = \lvert \lambda(\beta) \rvert$ since complex conjugation preserves lengths of vectors. Since $\lambda(\beta)$ is an even function infinitely differentiable at zero, its Taylor series contains only even powers of $\beta$.
\end{proof}

\section*{Problem 4}

\begin{thm}
The relationship between the order of accuracy of the truncation error $p$ and the leading order term in Taylor expansion of $\lvert \lambda(\beta) \rvert$ is $2q = p + 1$ when $p$ is odd, and $2q = p + 2$ when $p$ is even. 
\end{thm}

\begin{proof}

The order of the truncation error is $ O(\frac{\lvert e^{-\sigma\beta} - \lambda(\beta) \rvert}{\beta}) = O(\beta^{p})$.

Due to the reverse triangle inequality, $$ 1 - \lvert \lambda(\beta) \rvert \le \lvert e^{-\sigma\beta} - \lambda(\beta) \rvert \Longleftrightarrow O(\beta^{2q}) \le O(\beta^{p+1})$$

If $p$ is odd, then $p+1$ is even, and the smallest $q$ for which the inequality is satisfied is $q = \frac{p+1}{2} \Longleftrightarrow 2q = p+1$.

If $p$ is even, then $p+1$ is odd, and the smallest $q$ for which the inequality is satisfied is $q = \frac{(p+1)+1}{2} \Longleftrightarrow 2q = p+2$ (i.e. $2q$ must be one order smaller than $p+1$ in order for $2q$ to be an even number).

\end{proof}

\section*{Problem 5}

\begin{thm}
The convergence rate of Fromm's method is $O(h^3)$ when $\sigma = 0.5$
\end{thm}

\begin{proof}
Since the amplitude error is 
$$ \lvert \lambda(\beta) \rvert -1 = \frac{\sigma(\sigma-1)(\sigma^2 - \sigma + 1)}{8} \beta^4 + O(\beta^5) = O(\beta^4)$$
when $\sigma = 0.5$, and since the phase error is
$$ e^{-i\delta(\sigma,\beta)} = \frac{2\sigma^2- 3\sigma + 1}{12} \beta^3 + O(\beta^5) = \frac{(2\sigma- 1)(\sigma - 1)}{12} \beta^3 + O(\beta^5) = O(\beta^5) $$

it follows that the amplitude error dominates the local truncation error, since the amplitude error is one order larger than the phase error. 

Thus, the local truncation error of Fromm's method when $\sigma = 0.5$ is $$ \frac{O(\beta^4)}{\Delta t} = \frac{O(h^4)}{h} = O(h^3)$$

which explains the computed third-order convergence rate of Fromm's method with $\sigma = 0.5$ and Gaussian Pulse initial condition.

\end{proof}

% \bibliographystyle{amsplain}
% \begin{thebibliography}{n} %% n is number of items, or the largest label
% 
% \bibitem{1}\label{some label - optional} A.\,U. Thor, (not Thor, A.U.!)
% \emph{Title of paper},
% J. Math. \textbf{99} (2008), 111--222.
% 
% \bibitem{2} A.\,U. Thor,
% \emph{Title of paper},
% in: E. Ditor (ed.), \emph{Title of Book}, Publisher, City, Year, 888--999.
% 
% \end{thebibliography}

\end{document}

%% To be filled in the journal office:

@author:
@affiliation:
@title:
@language: English
@pages:
@classification1:
@classification2:
@keywords:
@abstract:
@filename:
@EOI


